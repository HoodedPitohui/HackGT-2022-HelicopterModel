{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(given_path, file_name):\n",
    "    metars_path = os.path.join(given_path, file_name)\n",
    "    metars_data = pd.read_csv(metars_path)\n",
    "    return metars_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>station_id</th>\n",
       "      <th>observation_time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>temp_c</th>\n",
       "      <th>dewpoint_c</th>\n",
       "      <th>wind_dir_degrees</th>\n",
       "      <th>wind_speed_kt</th>\n",
       "      <th>wind_gust_kt</th>\n",
       "      <th>...</th>\n",
       "      <th>maxT24hr_c</th>\n",
       "      <th>minT24hr_c</th>\n",
       "      <th>precip_in</th>\n",
       "      <th>pcp3hr_in</th>\n",
       "      <th>pcp6hr_in</th>\n",
       "      <th>pcp24hr_in</th>\n",
       "      <th>snow_in</th>\n",
       "      <th>vert_vis_ft</th>\n",
       "      <th>metar_type</th>\n",
       "      <th>elevation_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KBCT 220253Z 35007KT 10SM VCTS BKN050 22/17 A3...</td>\n",
       "      <td>KBCT</td>\n",
       "      <td>2022-10-22T02:53:00Z</td>\n",
       "      <td>26.38</td>\n",
       "      <td>-80.10</td>\n",
       "      <td>22.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>METAR</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YSNF 220252Z AUTO 09007KT 9999 -SHRA SCT020 SC...</td>\n",
       "      <td>YSNF</td>\n",
       "      <td>2022-10-22T02:52:00Z</td>\n",
       "      <td>-29.03</td>\n",
       "      <td>167.93</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPECI</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YCOM 220252Z AUTO 01013KT 5000 // SCT013 SCT02...</td>\n",
       "      <td>YCOM</td>\n",
       "      <td>2022-10-22T02:52:00Z</td>\n",
       "      <td>-36.30</td>\n",
       "      <td>148.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPECI</td>\n",
       "      <td>930.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PAFM 220252Z AUTO 12003KT 10SM FEW004 SCT015 O...</td>\n",
       "      <td>PAFM</td>\n",
       "      <td>2022-10-22T02:52:00Z</td>\n",
       "      <td>67.10</td>\n",
       "      <td>-157.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPECI</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PABV 220252Z AUTO 05003KT 10SM BKN004 02/02 A2...</td>\n",
       "      <td>PABV</td>\n",
       "      <td>2022-10-22T02:52:00Z</td>\n",
       "      <td>61.42</td>\n",
       "      <td>-149.52</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPECI</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4767</th>\n",
       "      <td>MMGM 222340Z 20008KT 10SM SCT030 BKN120 29/26 ...</td>\n",
       "      <td>MMGM</td>\n",
       "      <td>2022-10-22T23:40:00Z</td>\n",
       "      <td>27.95</td>\n",
       "      <td>-110.92</td>\n",
       "      <td>29.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>METAR</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4768</th>\n",
       "      <td>MMCV 222340Z 16009KT 10SM BKN250 26/15 A2988 R...</td>\n",
       "      <td>MMCV</td>\n",
       "      <td>2022-10-22T23:40:00Z</td>\n",
       "      <td>23.72</td>\n",
       "      <td>-98.97</td>\n",
       "      <td>26.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>METAR</td>\n",
       "      <td>230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4769</th>\n",
       "      <td>MMCN 222340Z 24005KT 10SM BKN210 29/20 A2973 R...</td>\n",
       "      <td>MMCN</td>\n",
       "      <td>2022-10-22T23:40:00Z</td>\n",
       "      <td>27.40</td>\n",
       "      <td>-109.83</td>\n",
       "      <td>29.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>METAR</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4770</th>\n",
       "      <td>MMCB 222340Z 00000KT 9SM SCT015 BKN080 BKN250 ...</td>\n",
       "      <td>MMCB</td>\n",
       "      <td>2022-10-22T23:40:00Z</td>\n",
       "      <td>18.83</td>\n",
       "      <td>-99.27</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>METAR</td>\n",
       "      <td>1281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4771</th>\n",
       "      <td>MMAS 222340Z 19005KT 9SM SCT100 SCT200 22/07 A...</td>\n",
       "      <td>MMAS</td>\n",
       "      <td>2022-10-22T23:40:00Z</td>\n",
       "      <td>21.70</td>\n",
       "      <td>-102.32</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>METAR</td>\n",
       "      <td>1866.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14325 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               raw_text station_id  \\\n",
       "0     KBCT 220253Z 35007KT 10SM VCTS BKN050 22/17 A3...       KBCT   \n",
       "1     YSNF 220252Z AUTO 09007KT 9999 -SHRA SCT020 SC...       YSNF   \n",
       "2     YCOM 220252Z AUTO 01013KT 5000 // SCT013 SCT02...       YCOM   \n",
       "3     PAFM 220252Z AUTO 12003KT 10SM FEW004 SCT015 O...       PAFM   \n",
       "4     PABV 220252Z AUTO 05003KT 10SM BKN004 02/02 A2...       PABV   \n",
       "...                                                 ...        ...   \n",
       "4767  MMGM 222340Z 20008KT 10SM SCT030 BKN120 29/26 ...       MMGM   \n",
       "4768  MMCV 222340Z 16009KT 10SM BKN250 26/15 A2988 R...       MMCV   \n",
       "4769  MMCN 222340Z 24005KT 10SM BKN210 29/20 A2973 R...       MMCN   \n",
       "4770  MMCB 222340Z 00000KT 9SM SCT015 BKN080 BKN250 ...       MMCB   \n",
       "4771  MMAS 222340Z 19005KT 9SM SCT100 SCT200 22/07 A...       MMAS   \n",
       "\n",
       "          observation_time  latitude  longitude  temp_c  dewpoint_c  \\\n",
       "0     2022-10-22T02:53:00Z     26.38     -80.10    22.0        17.0   \n",
       "1     2022-10-22T02:52:00Z    -29.03     167.93    18.0        16.0   \n",
       "2     2022-10-22T02:52:00Z    -36.30     148.97     NaN         NaN   \n",
       "3     2022-10-22T02:52:00Z     67.10    -157.85     1.0         0.0   \n",
       "4     2022-10-22T02:52:00Z     61.42    -149.52     2.0         2.0   \n",
       "...                    ...       ...        ...     ...         ...   \n",
       "4767  2022-10-22T23:40:00Z     27.95    -110.92    29.0        26.0   \n",
       "4768  2022-10-22T23:40:00Z     23.72     -98.97    26.0        15.0   \n",
       "4769  2022-10-22T23:40:00Z     27.40    -109.83    29.0        20.0   \n",
       "4770  2022-10-22T23:40:00Z     18.83     -99.27    25.0        19.0   \n",
       "4771  2022-10-22T23:40:00Z     21.70    -102.32    22.0         7.0   \n",
       "\n",
       "      wind_dir_degrees  wind_speed_kt  wind_gust_kt  ...  maxT24hr_c  \\\n",
       "0                350.0            7.0           NaN  ...         NaN   \n",
       "1                 90.0            7.0           NaN  ...         NaN   \n",
       "2                 10.0           13.0           NaN  ...         NaN   \n",
       "3                120.0            3.0           NaN  ...         NaN   \n",
       "4                 50.0            3.0           NaN  ...         NaN   \n",
       "...                ...            ...           ...  ...         ...   \n",
       "4767             200.0            8.0           NaN  ...         NaN   \n",
       "4768             160.0            9.0           NaN  ...         NaN   \n",
       "4769             240.0            5.0           NaN  ...         NaN   \n",
       "4770               0.0            0.0           NaN  ...         NaN   \n",
       "4771             190.0            5.0           NaN  ...         NaN   \n",
       "\n",
       "      minT24hr_c  precip_in pcp3hr_in pcp6hr_in pcp24hr_in snow_in  \\\n",
       "0            NaN        NaN       NaN       NaN        NaN     NaN   \n",
       "1            NaN        NaN       NaN       NaN        NaN     NaN   \n",
       "2            NaN        NaN       NaN       NaN        NaN     NaN   \n",
       "3            NaN      0.005       NaN       NaN        NaN     NaN   \n",
       "4            NaN        NaN       NaN       NaN        NaN     NaN   \n",
       "...          ...        ...       ...       ...        ...     ...   \n",
       "4767         NaN        NaN       NaN       NaN        NaN     NaN   \n",
       "4768         NaN        NaN       NaN       NaN        NaN     NaN   \n",
       "4769         NaN        NaN       NaN       NaN        NaN     NaN   \n",
       "4770         NaN        NaN       NaN       NaN        NaN     NaN   \n",
       "4771         NaN        NaN       NaN       NaN        NaN     NaN   \n",
       "\n",
       "     vert_vis_ft metar_type elevation_m  \n",
       "0            NaN      METAR         3.0  \n",
       "1            NaN      SPECI       113.0  \n",
       "2            NaN      SPECI       930.0  \n",
       "3            NaN      SPECI        79.0  \n",
       "4            NaN      SPECI        21.0  \n",
       "...          ...        ...         ...  \n",
       "4767         NaN      METAR        13.0  \n",
       "4768         NaN      METAR       230.0  \n",
       "4769         NaN      METAR        57.0  \n",
       "4770         NaN      METAR      1281.0  \n",
       "4771         NaN      METAR      1866.0  \n",
       "\n",
       "[14325 rows x 44 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_path = os.path.abspath(os.path.join(os.pardir, 'data'))\n",
    "given_data_1 = parse_data(save_path, 'metars_cache_1.csv')\n",
    "given_data_2 = parse_data(save_path, 'metars_test_cache.csv')\n",
    "given_data_3 = parse_data(save_path, 'metars_test2_cache.csv')\n",
    "\n",
    "# Concatenate all of these DataFrames\n",
    "given_data = pd.concat([given_data_1, given_data_2, given_data_3])\n",
    "\n",
    "display(given_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some basic cleaning to get rid of rows that are missing lat/long, since that's the bare minimum we need\n",
    "cleaned_data = given_data.dropna(axis=0, subset=['latitude', 'longitude'])\n",
    "cleaned_data = cleaned_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_usa(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Takes in world data and crudely restricts to just lat/long values corresponding to the lower 48\"\"\"\n",
    "\n",
    "    # We'll be using latitude bounds of [24, 49] and longitude bounds of [-125, -67] based on https://www.findlatitudeandlongitude.com/l/Lower+48/4315442/\n",
    "    return df.loc[(df['latitude'] >= 24) & (df['latitude'] <= 49) & (df['longitude'] >= -125) & (df['longitude'] <= -67)]\n",
    "\n",
    "# Get a rough estimate of the data corresponding to the US (minus Alaska and Hawaii)\n",
    "usa_data = filter_usa(cleaned_data)\n",
    "\n",
    "# Also, because 'Murica, let's change the units from C to F\n",
    "usa_data['temp_f'] = usa_data['temp_c'].apply(lambda x: (x * (9.0 / 5.0) + 32))\n",
    "usa_data['dewpoint_f'] = usa_data['dewpoint_c'].apply(lambda x: (x * (9.0 / 5.0) + 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def random_downsample():\n",
    "    cleaned_usa = usa_data.dropna(axis=0, subset=['temp_c', 'dewpoint_c', 'wind_speed_kt', 'visibility_statute_mi'])\n",
    "    cleaned_usa = cleaned_usa.reset_index(drop=True)\n",
    "\n",
    "    print(\"Number of Rows: \", len(cleaned_usa.index))\n",
    "    speci_data = cleaned_usa.loc[cleaned_usa['metar_type'] == 'SPECI']\n",
    "    print(\"Number of SPECI Rows: \", len(speci_data.index))\n",
    "\n",
    "    metar_data = cleaned_usa.loc[cleaned_usa['metar_type'] == 'METAR']\n",
    "    print(\"Number of METAR Rows: \", len(metar_data.index))\n",
    "    downsized_metar_data = metar_data.sample(n=len(speci_data.index))\n",
    "\n",
    "    # Put together the SPECI data and sampled METAR data\n",
    "    combined_data = pd.concat([speci_data, downsized_metar_data])\n",
    "    print(\"Size of Re-Balanced/Sampled Dataset: \", len(combined_data.index))\n",
    "\n",
    "    inputs = combined_data.loc[:, ['temp_c', 'dewpoint_c', 'wind_speed_kt', 'visibility_statute_mi']]\n",
    "\n",
    "    outputs = combined_data.loc[:, 'metar_type']\n",
    "\n",
    "    inputs_train, inputs_test, outputs_train, outputs_test = train_test_split(inputs, outputs, test_size=0.2)\n",
    "    \n",
    "    # Scale the inputs metrics\n",
    "    scaler = StandardScaler()\n",
    "    scaled_train_arr = scaler.fit_transform(inputs_train)\n",
    "    scaled_train = pd.DataFrame(data=scaled_train_arr, columns=inputs.columns)\n",
    "    scaled_test_arr = scaler.fit_transform(inputs_test)\n",
    "    scaled_test = pd.DataFrame(data=scaled_test_arr, columns=inputs.columns)\n",
    "    return scaled_train, scaled_test, outputs_train, outputs_test\n",
    "\n",
    "def pre_smote():\n",
    "    cleaned_usa = usa_data.dropna(axis=0, subset=['visibility_statute_mi'])\n",
    "    cleaned_usa = cleaned_usa.reset_index(drop=True)\n",
    "\n",
    "    print(\"Number of Rows: \", len(cleaned_usa.index))\n",
    "\n",
    "    inputs = cleaned_usa.loc[:, ['visibility_statute_mi']]\n",
    "\n",
    "    outputs = cleaned_usa.loc[:, 'metar_type']\n",
    "\n",
    "    inputs_train, inputs_test, outputs_train, outputs_test = train_test_split(inputs, outputs, test_size=0.2)\n",
    "\n",
    "    # Scale the inputs metrics\n",
    "    scaler = StandardScaler()\n",
    "    scaled_train_arr = scaler.fit_transform(inputs_train)\n",
    "    scaled_train = pd.DataFrame(data=scaled_train_arr, columns=inputs.columns)\n",
    "    scaler = StandardScaler()\n",
    "    scaled_test_arr = scaler.fit_transform(inputs_test)\n",
    "    scaled_test = pd.DataFrame(data=scaled_test_arr, columns=inputs.columns)\n",
    "    return scaled_train, scaled_test, outputs_train, outputs_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows:  6589\n",
      "Number of SPECI Rows:  633\n",
      "Number of METAR Rows:  5956\n",
      "Size of Re-Balanced/Sampled Dataset:  1266\n"
     ]
    }
   ],
   "source": [
    "resampled_inputs_train, inputs_test, resampled_outputs_train, outputs_test = random_downsample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows:  6703\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visibility_statute_mi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7937</th>\n",
       "      <td>0.063795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2335</th>\n",
       "      <td>0.063795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6508</th>\n",
       "      <td>0.063795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>0.063795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7487</th>\n",
       "      <td>0.063795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>0.063795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7942</th>\n",
       "      <td>0.063795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165</th>\n",
       "      <td>0.063795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4221</th>\n",
       "      <td>0.063795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8154</th>\n",
       "      <td>0.063795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9698 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      visibility_statute_mi\n",
       "7937               0.063795\n",
       "2335               0.063795\n",
       "6508               0.063795\n",
       "1202               0.063795\n",
       "7487               0.063795\n",
       "...                     ...\n",
       "1828               0.063795\n",
       "7942               0.063795\n",
       "6165               0.063795\n",
       "4221               0.063795\n",
       "8154               0.063795\n",
       "\n",
       "[9698 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7937    SPECI\n",
       "2335    METAR\n",
       "6508    SPECI\n",
       "1202    METAR\n",
       "7487    SPECI\n",
       "        ...  \n",
       "1828    METAR\n",
       "7942    SPECI\n",
       "6165    SPECI\n",
       "4221    METAR\n",
       "8154    SPECI\n",
       "Name: metar_type, Length: 9698, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(sampling_strategy='minority')\n",
    "\n",
    "inputs_train, inputs_test, outputs_train, outputs_test = pre_smote()\n",
    "\n",
    "resampled_inputs_train, resampled_outputs_train = sm.fit_resample(inputs_train, outputs_train)\n",
    "\n",
    "# For some reason, the SMOTE implementation seems to leave the data in an unshuffled state. So I will manually reshuffle\n",
    "shuffle_order = np.random.permutation(resampled_inputs_train.index)\n",
    "resampled_inputs_train = resampled_inputs_train.reindex(shuffle_order)\n",
    "resampled_outputs_train = resampled_outputs_train.reindex(shuffle_order)\n",
    "\n",
    "\n",
    "display(resampled_inputs_train)\n",
    "display(resampled_outputs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8501118568232662\n",
      "Confusion Matrix: \n",
      " [[1125   80]\n",
      " [ 121   15]]\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logModel = LogisticRegression()\n",
    "\n",
    "logModel.fit(resampled_inputs_train, resampled_outputs_train)\n",
    "\n",
    "pred_output = logModel.predict(inputs_test)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(outputs_test, pred_output))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(outputs_test, pred_output))\n",
    "\n",
    "speci_counter = 0\n",
    "for x in range(len(pred_output)):\n",
    "    if pred_output[x] == 'SPECI':\n",
    "        speci_counter += 1\n",
    "\n",
    "print(speci_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows:  6703\n"
     ]
    }
   ],
   "source": [
    "cleaned_usa = usa_data.dropna(axis=0, subset=['visibility_statute_mi'])\n",
    "cleaned_usa = cleaned_usa.reset_index(drop=True)\n",
    "\n",
    "print(\"Number of Rows: \", len(cleaned_usa.index))\n",
    "\n",
    "inputs = cleaned_usa.loc[:, ['visibility_statute_mi']]\n",
    "\n",
    "outputs = cleaned_usa.loc[:, 'metar_type']\n",
    "\n",
    "# Scale the inputs metrics\n",
    "scaler = StandardScaler()\n",
    "scaled_inputs_arr = scaler.fit_transform(inputs)\n",
    "scaled_inputs = pd.DataFrame(data=scaled_inputs_arr, columns=inputs.columns)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(sampling_strategy='minority')\n",
    "\n",
    "resampled_inputs, resampled_outputs = sm.fit_resample(inputs, outputs)\n",
    "\n",
    "# For some reason, the SMOTE implementation seems to leave the data in an unshuffled state. So I will manually reshuffle\n",
    "shuffle_order = np.random.permutation(resampled_inputs.index)\n",
    "resampled_inputs = resampled_inputs.reindex(shuffle_order)\n",
    "resampled_outputs = resampled_outputs.reindex(shuffle_order)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "finalLogModel = LogisticRegression()\n",
    "\n",
    "finalLogModel.fit(resampled_inputs, resampled_outputs)\n",
    "\n",
    "import pickle\n",
    "pickle.dump(finalLogModel, open('model', 'ab'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "pickle.load(open('model.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8583146905294556\n",
      "Confusion Matrix: \n",
      " [[1138   67]\n",
      " [ 123   13]]\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# With this for some reason, only visibility_statute gives decent results. Even including the others drops accuracy down to 0.36\n",
    "\n",
    "clf = DecisionTreeClassifier(ccp_alpha=0.0001)\n",
    "clf.fit(resampled_inputs, resampled_outputs)\n",
    "\n",
    "pred_output = clf.predict(inputs_test)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(outputs_test, pred_output))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(outputs_test, pred_output))\n",
    "\n",
    "speci_counter = 0\n",
    "for x in range(len(pred_output)):\n",
    "    if pred_output[x] == 'SPECI':\n",
    "        speci_counter += 1\n",
    "\n",
    "print(speci_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8553318419090231\n",
      "Confusion Matrix: \n",
      " [[1134   71]\n",
      " [ 123   13]]\n",
      "84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(C=0.01)\n",
    "svc.fit(resampled_inputs, resampled_outputs)\n",
    "\n",
    "pred_output = svc.predict(inputs_test)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(outputs_test, pred_output))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(outputs_test, pred_output))\n",
    "\n",
    "speci_counter = 0\n",
    "for x in range(len(pred_output)):\n",
    "    if pred_output[x] == 'SPECI':\n",
    "        speci_counter += 1\n",
    "\n",
    "print(speci_counter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('hackgt22')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "653db938998b6f4b12e46e0d026c249322777d3180e660da32c69a4e70d654ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
